{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import datetime\n",
    "import os \n",
    "import sys\n",
    "import methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border_msg(msg):\n",
    "    row = len(msg)\n",
    "    h = ''.join(['+'] + ['-' *row] + ['+'])\n",
    "    result= h + '\\n'\"|\"+msg+\"|\"'\\n' + h\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offers(file):\n",
    "    '''\n",
    "    Read in raw offer sheet\n",
    "    file - eg. \"/Users/yanangao/Desktop/Irvine & Venice Combined Files/Offer Sheet by Advertiser.csv\"\n",
    "    Return: \n",
    "        df: processed offer sheet\n",
    "    '''\n",
    "    df = pd.read_csv(\n",
    "        file,\n",
    "        encoding='latin-1'\n",
    "    )\n",
    "    \n",
    "    df = df.dropna(subset=['Hitpath Offer ID'])\n",
    "    df['Hitpath Offer ID'] = df['Hitpath Offer ID'].astype(int).astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ea(file):\n",
    "    '''\n",
    "    Read in Email Analyst file\n",
    "    file - eg. \"/Users/yanangao/Desktop/Irvine & Venice Combined Files/Dash - Master EA.xlsx\"\n",
    "    returns:\n",
    "        df: processed EA file (with cleaned subject line, and regrouped by 'date_received', 'sender_domain', 'sub_clean')\n",
    "    '''\n",
    "    df = pd.DataFrame(pd.read_excel(file))\n",
    "\n",
    "    # get subset of ibr data\n",
    "    df = df.rename(columns = {'overall_inbox_placement':'overall_inbox_percent'})\n",
    "    attr = ['date_received','sender_domain', 'subject', 'aol_inbox_percent', 'actual_aol_volume', 'google_inbox_percent', 'actual_google_volume',\n",
    "           'yahoo_inbox_percent', 'actual_yahoo_volume', 'outlook_inbox_percent', 'actual_outlook_volume',\n",
    "           'global_isps_inbox_percent', 'actual_global_isps_volume', 'actual_overall_volume','overall_inbox_percent', 'overall_weighted_inbox_placement']\n",
    "    df = df[attr]\n",
    "\n",
    "    # create columns \n",
    "    for j in ['aol', 'google', 'yahoo', 'outlook', 'global_isps', 'overall']:\n",
    "        df['%s_inbox_percent' % j] = df['%s_inbox_percent' % j] / 100\n",
    "        df['%s_action_volume' % j] = df['actual_%s_volume' % j] * df['%s_inbox_percent' % j]\n",
    "\n",
    "    df['overall_weighted_inbox_placement'] = df['overall_weighted_inbox_placement']/100 # could be useless??\n",
    "\n",
    "    # clean subject line\n",
    "#     df['sub_clean'] = df['subject'].str.replace('[REDACTED] ', '',regex=False).str.replace(\n",
    "#         '[REDACTED]', '',regex=False).str.rstrip(' !.?-').str.lstrip(' -,')\n",
    "    \n",
    "    df['sub_clean'] = df['subject'].str.replace('[REDACTED]', '',regex=False).str.replace(\n",
    "        '[REDACTED]', '',regex=False).str.rstrip(' !.?-').str.lstrip(' -,')\n",
    "\n",
    "#     # create and clean the sub_clean column's subject with functions imported from methods.py: Nicholas' regex function\n",
    "#     df.insert(2, 'sub_clean', df['subject'])\n",
    "#     for find, replace in Functions_lib.findReplaceDict.items():\n",
    "#         Functions_lib.replaceCol(df['sub_clean'], find, replace)   \n",
    "#     print(f'{len(df)} rows in EA file before combination')\n",
    "\n",
    "    print(\"\\n--------EA file report--------\\n\")\n",
    "    print(\"EA rows before combination\",df.shape)\n",
    "\n",
    "    df = df.groupby(['date_received', 'sender_domain', 'sub_clean']).agg({'actual_aol_volume':'sum','actual_google_volume':'sum',\n",
    "                                                                                'actual_yahoo_volume':'sum','actual_outlook_volume':'sum',\n",
    "                                                                                'actual_global_isps_volume':'sum','actual_overall_volume':'sum',\n",
    "                                                                                'aol_action_volume':'sum','google_action_volume':'sum',\n",
    "                                                                                'yahoo_action_volume':'sum','outlook_action_volume':'sum',\n",
    "                                                                                'global_isps_action_volume':'sum','overall_action_volume':'sum'}).reset_index(drop = False)\n",
    "\n",
    "    for i in ['aol', 'google', 'yahoo', 'outlook', 'global_isps', 'overall']:\n",
    "        df['%s_inbox_percent' % i] = df['%s_action_volume' % i] / df['actual_%s_volume' % i]\n",
    "\n",
    "    # create index_i and format date\n",
    "    df['date'] = pd.to_datetime(df['date_received'], format = '%m/%d/%Y')\n",
    "    df['index_i'] = df.index\n",
    "    print(\"EA rows after combination\",df.shape)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ea(file):\n",
    "#     '''\n",
    "#     Read in Email Analyst file\n",
    "#     file - eg. \"/Users/yanangao/Desktop/Last 30 Days-5.22.19 -6.15.19/EA_5.22.19-6.15.19.csv\"\n",
    "#     '''\n",
    "#     df = pd.DataFrame(pd.read_csv(file))\n",
    "\n",
    "#     # get subset of ibr data\n",
    "#     df = df.rename(columns = {'overall_inbox_placement':'overall_inbox_percent'})\n",
    "#     attr = ['date_received','sender_domain', 'subject', 'aol_inbox_percent', 'actual_aol_volume', 'google_inbox_percent', 'actual_google_volume',\n",
    "#            'yahoo_inbox_percent', 'actual_yahoo_volume', 'outlook_inbox_percent', 'actual_outlook_volume',\n",
    "#            'global_isps_inbox_percent', 'actual_global_isps_volume', 'actual_overall_volume','overall_inbox_percent', 'overall_weighted_inbox_placement']\n",
    "#     df = df[attr]\n",
    "\n",
    "#     # create columns \n",
    "#     for j in ['aol', 'google', 'yahoo', 'outlook', 'global_isps', 'overall']:\n",
    "#         df['%s_inbox_percent' % j] = df['%s_inbox_percent' % j] / 100\n",
    "#         df['%s_action_volume' % j] = df['actual_%s_volume' % j] * df['%s_inbox_percent' % j]\n",
    "\n",
    "#     df['overall_weighted_inbox_placement'] = df['overall_weighted_inbox_placement']/100 # could be useless??\n",
    "\n",
    "#     # clean subject line\n",
    "# #     df['sub_clean'] = df['subject'].str.replace('[REDACTED] ', '',regex=False).str.replace(\n",
    "# #         '[REDACTED]', '',regex=False).str.rstrip(' !.?-').str.lstrip(' -,')\n",
    "    \n",
    "#     df['sub_clean'] = df['subject'].str.replace('[REDACTED]', '',regex=False).str.replace(\n",
    "#         '[REDACTED]', '',regex=False).str.rstrip(' !.?-').str.lstrip(' -,')\n",
    "\n",
    "# #     # create and clean the sub_clean column's subject with functions imported from methods.py: Nicholas' regex function\n",
    "# #     df.insert(2, 'sub_clean', df['subject'])\n",
    "# #     for find, replace in Functions_lib.findReplaceDict.items():\n",
    "# #         Functions_lib.replaceCol(df['sub_clean'], find, replace)   \n",
    "# #     print(f'{len(df)} rows in EA file before combination')\n",
    "\n",
    "#     print(\"\\n--------EA file report--------\\n\")\n",
    "#     print(\"EA rows before combination\",df.shape)\n",
    "\n",
    "#     df = df.groupby(['date_received', 'sender_domain', 'sub_clean']).agg({'actual_aol_volume':'sum','actual_google_volume':'sum',\n",
    "#                                                                                 'actual_yahoo_volume':'sum','actual_outlook_volume':'sum',\n",
    "#                                                                                 'actual_global_isps_volume':'sum','actual_overall_volume':'sum',\n",
    "#                                                                                 'aol_action_volume':'sum','google_action_volume':'sum',\n",
    "#                                                                                 'yahoo_action_volume':'sum','outlook_action_volume':'sum',\n",
    "#                                                                                 'global_isps_action_volume':'sum','overall_action_volume':'sum'}).reset_index(drop = False)\n",
    "\n",
    "#     for i in ['aol', 'google', 'yahoo', 'outlook', 'global_isps', 'overall']:\n",
    "#         df['%s_inbox_percent' % i] = df['%s_action_volume' % i] / df['actual_%s_volume' % i]\n",
    "\n",
    "#     # create index_i and format date\n",
    "#     df['date'] = pd.to_datetime(df['date_received'], format = '%m/%d/%Y')\n",
    "#     df['index_i'] = df.index\n",
    "#     print(\"EA rows after combination\",df.shape)\n",
    "    \n",
    "#     return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailoredmail(file,domainNames):\n",
    "    '''\n",
    "    Read in TailoredMail raw file\n",
    "    file - eg. \"/Users/yanangao/Desktop/Irvine & Venice Combined Files/Dash - Master Tailored Mail.xlsx\"\n",
    "    returns:\n",
    "        df: processed TM file (with cleaned subject line)\n",
    "    '''\n",
    "    df = pd.read_excel(file)\n",
    "    df = df[[\n",
    "        'messageid','emailssent','num_deliveries','num_unique_opens','num_unique_clicks','num_contact_loss',\n",
    "        'delivery_rate','open_rate','click_rate','click_through_rate','contact_loss_rate',\n",
    "    ]]\n",
    "    df = df.rename(columns={\n",
    "        'messageid':'Message',\n",
    "        'emailssent':'Sent',\n",
    "        'num_deliveries':'Delivered',\n",
    "        'num_unique_opens':'Opens',\n",
    "        'num_unique_clicks':'Clicks',\n",
    "        'num_contact_loss':'Contacts Lost',\n",
    "        'delivery_rate':'Delivery Rate',\n",
    "        'open_rate':'Open Rate',\n",
    "        'click_rate':'Click Rate',\n",
    "        'click_through_rate':'Click Through Rate',\n",
    "        'contact_loss_rate':'Contact Loss Rate'\n",
    "    })\n",
    "\n",
    "    header_list = [\n",
    "        'Message','Last Edited','Sent','Delivered',\n",
    "        'Delivery Rate','Opens','Open Rate','Clicks',\n",
    "        'Click Rate','Click Through Rate','Contacts Lost','Contact Loss Rate'\n",
    "    ]\n",
    "    df = df.reindex(columns = header_list)\n",
    "\n",
    "    # break message column\n",
    "    df = methods.SubjectBreaker(df,domainNames)\n",
    "    df['date_brt'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "    df['strmonth'] = df['date_brt'].dt.strftime('%B %-d, %Y')\n",
    "\n",
    "    #get opener (only for format checking purpose, will delete later)\n",
    "    df.insert(0, \"openers\", df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), allow_duplicates = True)\n",
    "\n",
    "\n",
    "    #clean subject\n",
    "    df['sub_clean'] = df['subject line'].str.replace(\"[firstname]’s\", '').str.replace(\n",
    "                                \"[firstname]'s\", '').str.replace(\"[firstname],\", '').str.replace(\n",
    "                                '[firstname]:', '').str.replace(\"[firstname]\", '').str.replace(\n",
    "                                '[firstname]', '').str.replace('[firstname]’s', '').str.replace('[lastname]', '').str.replace(\n",
    "                                '[city]', '').str.replace('{{state}}', '').str.replace(\n",
    "                                '[address1]', '').str.replace(\"{{state_abbrev}}\", '').str.replace(\"{{date}}\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "\n",
    "\n",
    "    df['sub_clean'] = df.apply(lambda x: x['sub_clean'].replace('[longdate]',x['strmonth']),axis =1)\n",
    "\n",
    "    # add 1 day \n",
    "    df['date_plus_one'] = df.date_brt + datetime.timedelta(days = 1)\n",
    "\n",
    "    #add index\n",
    "    #     df['index_b'] = df.index\n",
    "\n",
    "    # add ESP\n",
    "    df['ESP']  = 'Tailored Mail'\n",
    "\n",
    "    #     # add subaccount\n",
    "    #     df['sub_account'] = np.nan\n",
    "\n",
    "    print(\"\\n--------Tailored Mail file report--------\\n\")\n",
    "    print(\"# of Tailored Mail drops:\",df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable(file,domainNames):\n",
    "    '''\n",
    "    Read in Iterable file,\n",
    "    file - eg. \"/Users/yanangao/Desktop/Irvine & Venice Combined Files/Dash - Master Iterable.xlsx\"\n",
    "    Returns:\n",
    "        df: processed Iterable file (with subject line cleaned, and column name renamed)\n",
    "    '''\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # pre-processing of Iterable data\n",
    "    df = df[[\n",
    "        'name','send_size','total_emails_delivered','unique_emails_opens',\n",
    "        'unique_email_clicks',\n",
    "    ]]\n",
    "    df = df.groupby(['name']).agg({\n",
    "        'send_size':'sum',\n",
    "        'total_emails_delivered':'sum',\n",
    "        'unique_emails_opens':'sum',\n",
    "        'unique_email_clicks':'sum'\n",
    "    }).reset_index(drop = False)\n",
    "    df = df.rename(columns={\n",
    "        'name':'Message',\n",
    "        'send_size':'Sent',\n",
    "        'total_emails_delivered':'Delivered',\n",
    "        'unique_emails_opens':'Opens',\n",
    "        'unique_email_clicks':'Clicks'\n",
    "    })\n",
    "    df['Delivery Rate'] = df['Delivered']/df['Sent']\n",
    "    df['Open Rate'] = df['Opens']/df['Delivered']\n",
    "    df['Click Rate'] = df['Clicks']/df['Opens']\n",
    "    df['Click Through Rate'] = df['Clicks']/df['Delivered']\n",
    "    header_list = [\n",
    "        'Message','Last Edited','Sent','Delivered',\n",
    "        'Delivery Rate','Opens','Open Rate','Clicks',\n",
    "        'Click Rate','Click Through Rate','Contacts Lost','Contact Loss Rate'\n",
    "    ]\n",
    "    df = df.reindex(columns = header_list)\n",
    "\n",
    "    # break message column\n",
    "    df = methods.SubjectBreaker(df,domainNames)\n",
    "    df['date_brt'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "    df['strmonth'] = df['date_brt'].dt.strftime('%B %-d, %Y')\n",
    "\n",
    "    #get opener (only for format checking purpose, will delete later)\n",
    "    df.insert(0, \"openers\", df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), allow_duplicates = True)\n",
    "\n",
    "\n",
    "    #clean subject\n",
    "    df['sub_clean'] = df['subject line'].str.replace(\"{{firstname}}’s\", '').str.replace(\n",
    "                                \"{{firstname}}'s\", '').str.replace(\"{{firstname}},\", '').str.replace(\n",
    "                                '{{firstname}}:', '').str.replace(\"{{firstname}}\", '').str.replace(\n",
    "                                '{{firstname}}', '').str.replace('{{firstname}}’s', '').str.replace('{{lastname}}', '').str.replace(\n",
    "                                '{{city}}', '').str.replace('{{state}}', '').str.replace(\n",
    "                                '{{address1}}', '').str.replace(\"{{state_abbrev}}\", '').str.replace(\"{{date}}\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "\n",
    "\n",
    "    df['sub_clean'] = df.apply(lambda x: x['sub_clean'].replace('{{now}}',x['strmonth']),axis =1)\n",
    "\n",
    "    # add 1 day \n",
    "    df['date_plus_one'] = df.date_brt + datetime.timedelta(days = 1)\n",
    "\n",
    "    #add index\n",
    "#     df['index_b'] = df.index\n",
    "    \n",
    "    # add ESP\n",
    "    df['ESP']  = 'Iterable'\n",
    "    \n",
    "#     # add subaccount\n",
    "#     df['sub_account'] = np.nan\n",
    "    \n",
    "    print(\"\\n--------Iterable file report--------\\n\")\n",
    "    print(\"# of Iterable drops:\",df.shape)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def iterable(file,domainNames):\n",
    "#     '''\n",
    "#     Read in Iterable file,\n",
    "#     file - eg. \"/Users/yanangao/Desktop/Last 30 Days-5.22.19 -6.15.19/iterable_5.22.19-6.15.19.csv\"\n",
    "#     '''\n",
    "#     df = pd.read_csv(file)\n",
    "#     # pre-processing of Iterable data\n",
    "#     df = df[[\n",
    "#         'Campaign Name','Total Email Sends','Total Emails Delivered','Total Email Opens',\n",
    "#         'Total Emails Clicked',\n",
    "#     ]]\n",
    "\n",
    "#     df = df.groupby(['Campaign Name']).agg({\n",
    "#         'Total Email Sends':'sum',\n",
    "#         'Total Emails Delivered':'sum',\n",
    "#         'Total Email Opens':'sum',\n",
    "#         'Total Emails Clicked':'sum'\n",
    "#     }).reset_index(drop = False)\n",
    "\n",
    "#     df = df.rename(columns={\n",
    "#         'Campaign Name':'Message',\n",
    "#         'Total Email Sends':'Sent',\n",
    "#         'Total Emails Delivered':'Delivered',\n",
    "#         'Total Email Opens':'Opens',\n",
    "#         'Total Emails Clicked':'Clicks'\n",
    "#     })\n",
    "\n",
    "#     df['Delivery Rate'] = df['Delivered']/df['Sent']\n",
    "#     df['Open Rate'] = df['Opens']/df['Delivered']\n",
    "#     df['Click Rate'] = df['Clicks']/df['Delivered']\n",
    "#     df['Click Through Rate'] = df['Clicks']/df['Delivered']\n",
    "\n",
    "#     header_list = [\n",
    "#         'Message','Last Edited','Sent','Delivered',\n",
    "#         'Delivery Rate','Opens','Open Rate','Clicks',\n",
    "#         'Click Rate','Click Through Rate','Contacts Lost','Contact Loss Rate'\n",
    "#     ]\n",
    "#     df = df.reindex(columns = header_list)\n",
    "\n",
    "#     # break message column\n",
    "#     df = methods.SubjectBreaker(df,domainNames)\n",
    "#     df['date_brt'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "#     df['strmonth'] = df['date_brt'].dt.strftime('%B %-d, %Y')\n",
    "\n",
    "#     #get opener (only for format checking purpose, will delete later)\n",
    "#     df.insert(0, \"openers\", df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), allow_duplicates = True)\n",
    "\n",
    "\n",
    "#     #clean subject\n",
    "#     df['sub_clean'] = df['subject line'].str.replace(\"{{firstname}}’s\", '').str.replace(\n",
    "#                                 \"{{firstname}}'s\", '').str.replace(\"{{firstname}},\", '').str.replace(\n",
    "#                                 '{{firstname}}:', '').str.replace(\"{{firstname}}\", '').str.replace(\n",
    "#                                 '{{firstname}}', '').str.replace('{{firstname}}’s', '').str.replace('{{lastname}}', '').str.replace(\n",
    "#                                 '{{city}}', '').str.replace('{{state}}', '').str.replace(\n",
    "#                                 '{{address1}}', '').str.replace(\"{{state_abbrev}}\", '').str.replace(\"{{date}}\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "\n",
    "\n",
    "#     df['sub_clean'] = df.apply(lambda x: x['sub_clean'].replace('{{now}}',x['strmonth']),axis =1)\n",
    "\n",
    "#     # add 1 day \n",
    "#     df['date_plus_one'] = df.date_brt + datetime.timedelta(days = 1)\n",
    "\n",
    "#     #add index\n",
    "# #     df['index_b'] = df.index\n",
    "    \n",
    "#     # add ESP\n",
    "#     df['ESP']  = 'Iterable'\n",
    "    \n",
    "# #     # add subaccount\n",
    "# #     df['sub_account'] = np.nan\n",
    "    \n",
    "#     print(\"\\n--------Iterable file report--------\\n\")\n",
    "#     print(\"# of Iterable drops:\",df.shape)\n",
    "    \n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bronto(file,domainNames):\n",
    "    '''\n",
    "    Read in bronto file\n",
    "    file - eg. \"/Users/yanangao/Desktop/Irvine & Venice Combined Files/Dash - Master Bronto.xlsx\"\n",
    "    Return:\n",
    "        df: processed bronto file (with cleaned subject line)\n",
    "    '''\n",
    "    df = pd.read_excel(file)\n",
    "    df = df[[\n",
    "        'Message','Sent','Delivered','Delivery Rate','Opens','Open Rate','Clicks','Click Rate','Click Through Rate',\n",
    "        'Contacts Lost','Contact Loss Rate',\n",
    "    ]]\n",
    "#     df = df[[\n",
    "#         'message','sent','delivered','deliver_rate','opens','open_rate','clicks','click_rate','click_through-rate',\n",
    "#         'contacts_lost','contact_loss_rate',\n",
    "#     ]]\n",
    "#     df = df.rename(columns = {\n",
    "#         'message':'Message',\n",
    "#         'sent':'Sent',\n",
    "#         'delivered':'Delivered',\n",
    "#         'deliver_rate':'Delivery Rate',\n",
    "#         'Total Email Opens':'Opens',\n",
    "#         'open_rate':'Open Rate',\n",
    "#         'clicks':'Clicks',\n",
    "#         'click_rate':'Click Rate',\n",
    "#         'click_through-rate':'Click Through Rate',\n",
    "#         'contacts_lost':'Contacts Lost',\n",
    "#         'contact_loss_rate':'Contact Loss Rate'\n",
    "#     })\n",
    "    \n",
    "    # break message column\n",
    "    df = methods.SubjectBreaker(df,domainNames)\n",
    "\n",
    "    #get datetime\n",
    "    df['date_brt'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "    # print(df[df.date_brt.isna()][['Message']])\n",
    "    df['strmonth'] = df['date_brt'].dt.strftime('%B %-d, %Y')\n",
    "\n",
    "    #get opener (only for format checking purpose, will delete later)\n",
    "    df.insert(0, \"openers\", df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), allow_duplicates = True)\n",
    "\n",
    "    \n",
    "    #clean subject\n",
    "    df['sub_clean'] = df['subject line'].str.replace(\"%%firstname%%’s\", '').str.replace(\n",
    "                                \"%%firstname%%'s\", '').str.replace(\"%%firstname%%,\", '').str.replace(\n",
    "                                '%%firstname%%:', '').str.replace(\"%%firstname%%\", '').str.replace(\n",
    "                                '%%firstname%%', '').str.replace('%%lastname%%’s', '').str.replace('%%lastname%%', '').str.replace(\n",
    "                                '%%city%%', '').str.replace('%%state%%', '').str.replace(\n",
    "                                '%%address1%%', '').str.replace(\"%%state_abbrev%%\", '').str.replace(\"%%date%%\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "    \n",
    "    #clean subject \n",
    "#     df['sub_clean'] = df['subject line'].str.replace(\"%%firstname%%’s \", '').str.replace(\n",
    "#                                 \"%%firstname%%'s \", '').str.replace(\"%%firstname%%, \", '').str.replace(\n",
    "#                                 '%%firstname%%: ', '').str.replace(\"%%firstname%% \", '').str.replace(\n",
    "#                                 '%%firstname%%', '').str.replace('%%lastname%%’s', '').str.replace('%%lastname%%', '').str.replace(\n",
    "#                                 '%%city%% ', '').str.replace('%%city%%', '').str.replace('%%state%% ', '').str.replace(\n",
    "#                                 '%%address1%%', '').str.replace(\"%%state_abbrev%%\", '').str.replace(\"%%date%%\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "    df['sub_clean'] = df.apply(lambda x: x['sub_clean'].replace('%%!date%%',x['strmonth']),axis =1)\n",
    "\n",
    "\n",
    "    # add 1 day \n",
    "    df['date_plus_one'] = df.date_brt + datetime.timedelta(days = 1)\n",
    "\n",
    "    #add index\n",
    "#     df['index_b'] = df.index\n",
    "\n",
    "    # add ESP\n",
    "    df['ESP']  = 'Bronto'\n",
    "    \n",
    "#     # add sub account\n",
    "#     df['sub_account'] = \n",
    "    \n",
    "    print(\"\\n--------bronto file report--------\\n\")\n",
    "    # df.drop('openers', axis = 1, inplace = True)\n",
    "    print(\"# of Bronto drops:\",df.shape)\n",
    "    \n",
    "    border_msg('Check point I')\n",
    "    floatCol = df[[\n",
    "        'Sent','Delivered','Delivery Rate', 'Opens', 'Open Rate',\n",
    "        'Clicks', 'Click Rate','Click Through Rate', 'Contacts Lost',\n",
    "        'Contact Loss Rate',\n",
    "    ]]\n",
    "\n",
    "    obj_types = {col: set(map(type, floatCol[col])) for col in floatCol.select_dtypes(include=[object])}\n",
    "    if len(obj_types) == 0:\n",
    "        print(\"Passed Bronto column data type checking!\")\n",
    "    else:\n",
    "        print(\"Strings found in Bronto float columns!!!\")\n",
    "        print(obj_types)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bronto(file,domainNames):\n",
    "#     '''\n",
    "#     Read in bronto file\n",
    "#     file - eg. \"/Users/yanangao/Desktop/Last 30 Days-5.22.19 -6.15.19/bronto_5.22.19-6.15.19.csv\"\n",
    "#     '''\n",
    "#     df = pd.read_csv(file)\n",
    "    \n",
    "#     # create new open rate/click rate => to get more decimal places.\n",
    "#     df.drop(['Open Rate','Click Rate','Click Through Rate'],axis=1,inplace=True)\n",
    "#     df.insert(6,'Open Rate',df.Opens/df.Delivered)\n",
    "#     df.insert(8,'Click Rate',df.Clicks/df.Opens)\n",
    "#     df.insert(9,'Click Through Rate',df.Clicks/df.Delivered)\n",
    "\n",
    "#     # break message column\n",
    "#     df = methods.SubjectBreaker(df,domainNames)\n",
    "\n",
    "#     #get datetime\n",
    "#     df['date_brt'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "#     # print(df[df.date_brt.isna()][['Message']])\n",
    "#     df['strmonth'] = df['date_brt'].dt.strftime('%B %-d, %Y')\n",
    "\n",
    "#     #get opener (only for format checking purpose, will delete later)\n",
    "#     df.insert(0, \"openers\", df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), allow_duplicates = True)\n",
    "\n",
    "    \n",
    "#     #clean subject\n",
    "#     df['sub_clean'] = df['subject line'].str.replace(\"%%firstname%%’s\", '').str.replace(\n",
    "#                                 \"%%firstname%%'s\", '').str.replace(\"%%firstname%%,\", '').str.replace(\n",
    "#                                 '%%firstname%%:', '').str.replace(\"%%firstname%%\", '').str.replace(\n",
    "#                                 '%%firstname%%', '').str.replace('%%lastname%%’s', '').str.replace('%%lastname%%', '').str.replace(\n",
    "#                                 '%%city%%', '').str.replace('%%state%%', '').str.replace(\n",
    "#                                 '%%address1%%', '').str.replace(\"%%state_abbrev%%\", '').str.replace(\"%%date%%\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "    \n",
    "#     #clean subject \n",
    "# #     df['sub_clean'] = df['subject line'].str.replace(\"%%firstname%%’s \", '').str.replace(\n",
    "# #                                 \"%%firstname%%'s \", '').str.replace(\"%%firstname%%, \", '').str.replace(\n",
    "# #                                 '%%firstname%%: ', '').str.replace(\"%%firstname%% \", '').str.replace(\n",
    "# #                                 '%%firstname%%', '').str.replace('%%lastname%%’s', '').str.replace('%%lastname%%', '').str.replace(\n",
    "# #                                 '%%city%% ', '').str.replace('%%city%%', '').str.replace('%%state%% ', '').str.replace(\n",
    "# #                                 '%%address1%%', '').str.replace(\"%%state_abbrev%%\", '').str.replace(\"%%date%%\", '').str.lstrip(' -,').str.rstrip(' .?!-')\n",
    "#     df['sub_clean'] = df.apply(lambda x: x['sub_clean'].replace('%%!date%%',x['strmonth']),axis =1)\n",
    "    \n",
    "    \n",
    "#     # df['sub_clean']=df['subject line']\n",
    "#     # for find, replace in methods.findReplaceDict.items():\n",
    "#     #     methods.replaceCol(df['sub_clean'],find,replace)\n",
    "\n",
    "\n",
    "#     # add 1 day \n",
    "#     df['date_plus_one'] = df.date_brt + datetime.timedelta(days = 1)\n",
    "\n",
    "#     #add index\n",
    "# #     df['index_b'] = df.index\n",
    "\n",
    "#     # add ESP\n",
    "#     df['ESP']  = 'Bronto'\n",
    "    \n",
    "# #     # add sub account\n",
    "# #     df['sub_account'] = \n",
    "    \n",
    "#     print(\"\\n--------bronto file report--------\\n\")\n",
    "#     # df.drop('openers', axis = 1, inplace = True)\n",
    "#     print(\"# of Bronto drops:\",df.shape)\n",
    "    \n",
    "#     border_msg('Check point I')\n",
    "#     floatCol = df[[\n",
    "#         'Sent','Delivered','Delivery Rate', 'Opens', 'Open Rate',\n",
    "#         'Clicks', 'Click Rate','Click Through Rate', 'Contacts Lost',\n",
    "#         'Contact Loss Rate',\n",
    "#     ]]\n",
    "\n",
    "#     obj_types = {col: set(map(type, floatCol[col])) for col in floatCol.select_dtypes(include=[object])}\n",
    "#     if len(obj_types) == 0:\n",
    "#         print(\"Passed Bronto column data type checking!\")\n",
    "#     else:\n",
    "#         print(\"Strings found in Bronto float columns!!!\")\n",
    "#         print(obj_types)\n",
    "    \n",
    "#     return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(file,offers,domainNames):\n",
    "    '''\n",
    "    Read in revenue raw file from Outsource\n",
    "    file - eg. '/Users/yanangao/Desktop/Irvine & Venice Combined Files/Master Revenue.csv'\n",
    "    Return: \n",
    "        df: processed revenue file\n",
    "    '''\n",
    "    df = pd.read_csv(\n",
    "        file, \n",
    "        encoding = 'latin-1'\n",
    "    )\n",
    "    df = df.dropna(subset = ['Message'])\n",
    "    df = df.rename(columns = {'Campaign ID':'HitPath ID'})\n",
    "    \n",
    "    # replace string values (eg. #value?, no data, $revenue...) in revenue cols to nan\n",
    "    df[[\n",
    "        \"Revenue\", \"RPC\", \"Revenue CPM (eCPM)\",\"Cost CPM\",\"Cost per send\",\"Net Revenue\",\"Margin\",\"Conversions\"\n",
    "    ]] = df[[\n",
    "        \"Revenue\", \"RPC\", \"Revenue CPM (eCPM)\",\"Cost CPM\",\"Cost per send\",\"Net Revenue\",\"Margin\",\"Conversions\"\n",
    "    ]].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    \n",
    "\n",
    "    \n",
    "    df = methods.SubjectBreaker(df,domainNames)\n",
    "\n",
    "    df.insert(\n",
    "        0, \"data_provider\", \n",
    "        df.rest_.str.split(\"_\", expand = True)[0].str.rstrip(' .?!-').str.replace('AP','AP.I').str.replace('AP.I.I','AP.I').str.replace('LXCN','LXCN.PA').str.replace('LXCN.PA.PA','LXCN.PA').str.replace('I.CARDAP.IP','I.CARDAPP'), \n",
    "        allow_duplicates = True\n",
    "    )\n",
    "    df.insert(\n",
    "        0, \"openers\", \n",
    "        df.rest_.str.split(\"_\", expand = True)[1].str.rstrip(' .?!-').str.upper(), \n",
    "        allow_duplicates = True\n",
    "    )\n",
    "#     df.insert(\n",
    "#         0, \"\",\n",
    "        \n",
    "#     )\n",
    "    df['Date'] = pd.to_datetime(df.date_pt, format = '%m.%d.%y',errors='coerce')\n",
    "    print(\"\\n-------revenue file report---------\\n\")\n",
    "    rowsBeforeMerging = len(df)\n",
    "\n",
    "    # replace \"offer\" in revenue report with \"offer name\" in smartsheet\n",
    "    offerCol = offers[['Hitpath Offer ID','Offer Name']]\n",
    "    df = pd.merge(df,offerCol,how='left',left_on='Campaign ID',right_on='Hitpath Offer ID')\n",
    "    df.drop(['Offer','Hitpath Offer ID'],axis=1,inplace=True)\n",
    "    \n",
    "    rowsAfterMerging = len(df)\n",
    "    border_msg('Check point II')\n",
    "    if rowsBeforeMerging != rowsAfterMerging:\n",
    "        print(\"Duplicated HitPath IDs are found in Offer sheets!!!\")\n",
    "    else:\n",
    "        print(\"Passed duplicated HitPath ID checking!\")\n",
    "\n",
    "    df['index_craig'] = df.index\n",
    "\n",
    "    print(\"# of drops in Revenue report:\",len(df))\n",
    "    # Functions_lib.FormatChecker(df)\n",
    "    # print(errorrev[['Message']])\n",
    "    \n",
    "    border_msg('Check point III')\n",
    "    floatCol = df[[\n",
    "        'Delivered', 'Opens', 'Open Rate',\n",
    "        'Clicks', 'Click Rate','Revenue', 'RPC',\n",
    "        'Revenue CPM (eCPM)', 'Cost CPM', 'Cost per send', 'Net Revenue',\n",
    "        'Margin', \n",
    "    ]]\n",
    "\n",
    "    obj_types = {col: set(map(type, floatCol[col])) for col in floatCol.select_dtypes(include=[object])}\n",
    "    if len(obj_types) == 0:\n",
    "        print(\"Passed Revenue column data type checking!\")\n",
    "    else:\n",
    "        print(\"Strings found in Revenue float columns!!!\")\n",
    "        print(obj_types)\n",
    "        \n",
    "#     border_msg(\"Check point IV\")\n",
    "    \n",
    "\n",
    "#     df = df.drop('domain', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(file):\n",
    "    '''\n",
    "    Read in an email map tracking sheet\n",
    "    df - eg. 'mapping - 12.21.2019.csv'\n",
    "    '''\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[~(df.Status=='INACTIVE')&~(df['DP.DS or DP.DV if multiple sources using samePubID'].isna())]\n",
    "    df['From Domain ID'] = df['From Domain ID'].astype(int).astype(str)\n",
    "    df['Revenue Pub ID'] = df['Revenue Pub ID'].astype(int).astype(str)\n",
    "    df['DP.DS or DP.DV if multiple sources using samePubID'] = df['DP.DS or DP.DV if multiple sources using samePubID'].str.upper()\n",
    "\n",
    "    \n",
    "    ## create DP.DS.Domain.ESP.SA.PUBID list\n",
    "    df['uniqueV2'] = df['DP.DS or DP.DV if multiple sources using samePubID']+\"_\"+df['From Domain ID']+\"_\"+df['ESP ID']+\"_\"+df['ESP Sub Account ID']+\"_\"+df['Revenue Pub ID']\n",
    "    DPDSDomainESPSAPUBlist = list(df['uniqueV2'].unique())\n",
    "    \n",
    "    ## create DP.DS.Domain list\n",
    "    df['unique'] = df['DP.DS or DP.DV if multiple sources using samePubID']+\"_\"+df['From Domain ID']\n",
    "    DPDSDomainlist = list(df['unique'].unique())\n",
    "    \n",
    "    ## creat DP.DS list\n",
    "    DPDSlist = list(df['DP.DS or DP.DV if multiple sources using samePubID'].unique())\n",
    "    \n",
    "    ## create domainNames dictionary\n",
    "    domianNoDup = df[['From Domain','From Domain ID']].drop_duplicates(keep = 'first')\n",
    "    domainNames = pd.Series(domianNoDup['From Domain'].values,index=domianNoDup['From Domain ID']).to_dict()\n",
    "    \n",
    "    return DPDSDomainESPSAPUBlist, DPDSDomainlist,DPDSlist,domainNames,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mapping(file):\n",
    "#     '''\n",
    "#     Read in an email map tracking sheet\n",
    "#     df - eg. 'mapping - 12.21.2019.csv'\n",
    "#     '''\n",
    "#     df = pd.read_csv(file)\n",
    "#     df = df[~(df.Status=='INACTIVE')&~(df['DP.DS or DP.DV if multiple sources using samePubID'].isna())]\n",
    "#     df['From Domain ID'] = df['From Domain ID'].astype(int).astype(str)\n",
    "    \n",
    "#     ## create venice DP.DS.Domain list\n",
    "#     df['DP.DS or DP.DV if multiple sources using samePubID'] = df['DP.DS or DP.DV if multiple sources using samePubID'].str.upper()\n",
    "#     df['unique'] = df['DP.DS or DP.DV if multiple sources using samePubID']+\"_\"+df['From Domain ID']\n",
    "#     veniceList = list(df['unique'].unique())\n",
    "#     # add irvine DP.DS.Domain list\n",
    "#     irvineList = ['AP_1','SC.RF_2','SC.FHA_3','PMG.RF_2','PMG.DEBT_4','WC.RF_6',\n",
    "#                  'UPSD.RF_2','LXCN_5','LPG.RF_7','LPG.FHA_8',]\n",
    "#     DPDSDomainlist = veniceList + irvineList\n",
    "    \n",
    "#     ## create venice domainNames dictionary\n",
    "#     domianNoDup = df[['From Domain','From Domain ID']].drop_duplicates(keep = 'first')\n",
    "#     domainNames = pd.Series(domianNoDup['From Domain'].values,index=domianNoDup['From Domain ID']).to_dict()\n",
    "#     # add irvine domains\n",
    "#     IrvineDomainNames = {\n",
    "#         \"1\":'apply-portal.net',\n",
    "#         \"2\":'mortgage-assisting.com',\n",
    "#         \"3\":'fha-guide.com',\n",
    "#         \"4\":'app-portal.net',\n",
    "#         \"5\":'thepaleo.net',\n",
    "#         \"6\":'house-goals.com',\n",
    "#         \"7\":'yourupdatereport.com',\n",
    "#         \"8\":'thefhacapital.com',\n",
    "#     }\n",
    "#     domainNames.update(IrvineDomainNames)\n",
    "    \n",
    "#     return DPDSDomainlist,domainNames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduling(file):\n",
    "    '''\n",
    "    Read in an scheduling sheet\n",
    "    file - eg. 'scheduling - 12.21.2019.csv'\n",
    "    '''\n",
    "    df = pd.read_csv(file)\n",
    "   \n",
    "    # get date \n",
    "    df['Unique ID'] = df['Unique ID'].astype(str)\n",
    "    df.insert(0,\"Campaign ID\",df[\"Unique ID\"].str[0:4])\n",
    "    df.insert(1,\"date\",df['Unique ID'].str[4:9])\n",
    "\n",
    "    df.date = pd.to_numeric(df.date)\n",
    "    df.insert(0,\"Date\",df.date.fillna(80000).astype(int).apply(lambda x: datetime(*xldate_as_tuple(x,0))))\n",
    "\n",
    "    # get campaign id and data provider\n",
    "    # df['Campaign ID']=df['Campaign ID'].astype(str)\n",
    "    df[['data_provider', 'openers']] = df['Segment'].str.split('_', 1, expand = True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
